{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pickle\n",
    "import joblib\n",
    "import csv\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Check Chicago Crime Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 2016-2019 crime data\n",
    "crime_2016 = os.path.join(\"..\",\"Resources\", \"crime_clean_2016.csv\") \n",
    "crime_2017 = os.path.join(\"..\",\"Resources\", \"crime_clean_2017.csv\")\n",
    "crime_2018 = os.path.join(\"..\",\"Resources\", \"crime_clean_2018.csv\")\n",
    "crime_2019 = os.path.join(\"..\",\"Resources\", \"crime_clean_2019.csv\")\n",
    "\n",
    "crime_2016_df_final = pd.read_csv(crime_2016)\n",
    "crime_2017_df_final = pd.read_csv(crime_2017)\n",
    "crime_2018_df_final = pd.read_csv(crime_2018)\n",
    "\n",
    "# 2019 is the test data\n",
    "test_data = pd.read_csv(crime_2019)\n",
    "\n",
    "# Join datasets for 2016, 2017, and 2018 for the training data\n",
    "join1 = crime_2016_df_final.append(crime_2017_df_final)\n",
    "training_data = join1.append(crime_2018_df_final)\n",
    "X = training_data.append(test_data).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "number = preprocessing.LabelEncoder()\n",
    "c = X['location_description'].unique()\n",
    "b = X['primary_type'].unique()\n",
    "encoded_loc = number.fit_transform(c).astype('int')\n",
    "encoded_type = number.fit_transform(b).astype('int')\n",
    "loc_dict = dict(zip(c,encoded_loc))\n",
    "type_dict = dict(zip(b,encoded_type))\n",
    "\n",
    "file = os.path.join(\"..\",\"Resources\", \"loc_dict.csv\") \n",
    "\n",
    "with open(file, \"w\", newline='') as outfile:\n",
    "    w = csv.writer(outfile)\n",
    "    w.writerow(['loc', 'val'])\n",
    "    for key, val in loc_dict.items():\n",
    "        w.writerow([key, val])\n",
    "\n",
    "file = os.path.join(\"..\",\"Resources\", \"type_dict.csv\") \n",
    "\n",
    "with open(file, \"w\", newline='') as outfile:\n",
    "    w = csv.writer(outfile)\n",
    "    w.writerow(['type', 'val'])\n",
    "    for key, val in type_dict.items():\n",
    "        w.writerow([key, val])   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to Convert data to numbers\n",
    "def convert(data):\n",
    "    number = preprocessing.LabelEncoder()\n",
    "    data['date'] = number.fit_transform(data.date)\n",
    "    data['time'] = number.fit_transform(data.time)\n",
    "    data['block'] = number.fit_transform(data.block)\n",
    "    data['description'] = number.fit_transform(data.description)\n",
    "    data['location_description'] = number.fit_transform(data.location_description)\n",
    "    data['iucr'] = number.fit_transform(data.iucr)\n",
    "    data['fbi_code'] = number.fit_transform(data.fbi_code)\n",
    "    data['primary_type'] = number.fit_transform(data.primary_type)\n",
    "    data['domestic'] = number.fit_transform(data.domestic)\n",
    "    data['latitude'] = number.fit_transform(data.latitude)\n",
    "    data['longitude'] = number.fit_transform(data.longitude)\n",
    "    data['arrest'] = number.fit_transform(data.arrest)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to drop unneeded columns/keeping only features needed for model\n",
    "def set_data(data):\n",
    "    data = (data[[\n",
    "              #'date'\n",
    "              #'day'\n",
    "              'month'\n",
    "              #,'year'\n",
    "              #,'time'\n",
    "              ,'hour'\n",
    "              #,'month_day'\n",
    "              ,'day_of_week'\n",
    "              #,'district'\n",
    "              #,'block'\n",
    "              #,'ward'\n",
    "              #,'beat'\n",
    "              #,'community_area'\n",
    "              #,'description'\n",
    "              ,'location_description'\n",
    "              #,'x_coordinate'\n",
    "              #,'y_coordinate'\n",
    "              #,'iucr'\n",
    "              #,'fbi_code'\n",
    "              ,'primary_type'\n",
    "              #,'domestic'\n",
    "              #,'latitude'\n",
    "              #,'longitude'\n",
    "            ]])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncode the data\n",
    "X = convert(X)\n",
    "y = X[\"arrest\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = set_data(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2,test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data for SVM, requires normalization\n",
    "#reference: https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "y_train = np.array(y_train).reshape((len(y_train), 1),order='C')\n",
    "y_test = np.array(y_test).reshape((len(y_test), 1),order='C')\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model is faster with C-contiguous data\n",
    "#reference: https://scikit-learn.org/stable/modules/svm.html\n",
    "X_train_scaled = np.asarray(X_train_scaled, order='C')\n",
    "X_test_scaled = np.asarray(X_test_scaled, order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208961, 5)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208961,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.ravel().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(208962, 1)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Support vector machine linear classifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model = MLPClassifier( max_iter=175,activation='tanh',alpha=.00081,hidden_layer_sizes=(50,100,50), solver= 'adam'\n",
    "                      ,learning_rate='invscaling')\n",
    "\n",
    "model = model.fit(X_train_scaled, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'MLP_model.pkl'\n",
    "\n",
    "with open(filename, 'wb') as file:\n",
    "    pickle.dump(model, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MLP_model.joblib']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the model to disk\n",
    "filename = 'MLP_model.joblib'\n",
    "\n",
    "joblib.dump(model, filename) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Acc: 0.874\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.98      0.92    166376\n",
      "           1       0.83      0.47      0.60     42586\n",
      "\n",
      "    accuracy                           0.87    208962\n",
      "   macro avg       0.86      0.72      0.76    208962\n",
      "weighted avg       0.87      0.87      0.86    208962\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Predicting y for X_val\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "#Importing classification_report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Printing the accuracy\n",
    "print('Test Acc: %.3f' % model.score(X_test_scaled, y_test))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.3647481362652441, 0.32509049086755293, 0.3169068254465498, 0.3120769166524505, 0.3092045557147338, 0.30719124418026267, 0.3052612536726263, 0.30379741662418264, 0.30285946548081916, 0.3018359848485192, 0.3009467013722943, 0.30048011025995097, 0.29970846964696174, 0.2989561096050603, 0.2987986684045336, 0.29824317631337616, 0.2975749714510516, 0.2970053606544441, 0.29683140160374766, 0.29642338558921555, 0.2962407705149295, 0.295907192313715, 0.2952308772554499, 0.29523863710227566, 0.29482320874883605, 0.2945885672159632, 0.29428670354159203, 0.2938374488906878, 0.29362858712632073, 0.29333043572230666, 0.2930975205976804, 0.2928814049700022, 0.29248791357499077, 0.29226418702599494, 0.2921369894885515, 0.2918686556722558, 0.29146126931734956, 0.2912393758120024, 0.29092525767423766, 0.29087303123654856, 0.2905196115137932, 0.29022895866051335, 0.2900912459722708, 0.28989868256208395, 0.2894068526360305, 0.28933342677564844, 0.2891259729130389, 0.2887390204438351, 0.2886100721382923, 0.2885182393937425, 0.28799077691698927, 0.2878008804492252, 0.2877468794314217, 0.2873583782491329, 0.287316575799537, 0.287079388917678, 0.28672749487368954, 0.28673010520727243, 0.2866147896250225, 0.2861665103807437, 0.28599044752180086, 0.28557899642310347, 0.285547716666316, 0.28513581816895067, 0.28512978295492963, 0.28494949554415716, 0.2846280023741177, 0.2844333757923229, 0.2842813669093925, 0.28402287596847914, 0.28406046934656315, 0.2838246472930423, 0.28357149071356696, 0.28350363538571705, 0.28301809526530797, 0.28318636399109637, 0.28298823328847794, 0.2827765967636329, 0.2822829137867761, 0.2823018960973281, 0.2821434958075599, 0.28201536976132896, 0.28194536860321456, 0.28146401288546224, 0.2814710252454467, 0.2816484480008774, 0.2811074767707297, 0.2807139012836693, 0.28069426876058956, 0.28054389625050974, 0.2805424054842758, 0.28020667297946106, 0.28005613208747093, 0.2798553707307586, 0.28001553952469455, 0.2794394624580649, 0.2795368708236296, 0.2793128786309784, 0.27915716862591294, 0.2789480732408639, 0.27878890234042614, 0.2786724486593993, 0.2783275960236734, 0.27820695621541686, 0.27794188132018216, 0.2780810453445091, 0.27769490848150474, 0.2778177259549069, 0.2772758633802147, 0.27727389588800305, 0.2770662944268891, 0.2769619455933812, 0.2767407557073187, 0.276456312568077, 0.2764620319814304, 0.27629498951011633, 0.2761108235923698, 0.2759825560970553, 0.27583570861793755, 0.27570859022683347, 0.27548715585849426, 0.2755293922219735, 0.27512582897847, 0.27510380712555665, 0.27483120331652905, 0.2746860002871554, 0.2746853949393368, 0.2744493646375423, 0.2743741199298904, 0.2740442538046311, 0.27412373439081356, 0.27376750387930465, 0.27354633502186, 0.2736429107100955, 0.27339107572075483, 0.2732039803123274, 0.2730469651784183, 0.27316323513845997, 0.272930853830774, 0.2725472217100156, 0.27243291652540014, 0.27235591455543695, 0.2723689823346416, 0.2719519588237276, 0.27203646180369917, 0.2720472947217445, 0.27181175377407507, 0.27167048920687575, 0.2715444063693526, 0.27150317005024294, 0.27138359085946506, 0.2710030084314657, 0.27092879345559134, 0.27089218656900177, 0.2708541536918926, 0.2706682695715684, 0.27092838285480225, 0.27035612132451264, 0.2704988656800726, 0.27011417370243046, 0.2699858761905953, 0.26998907741342126, 0.2700322134167309, 0.2697761212250827, 0.26951509833622506, 0.2694634260770298, 0.2693163050278684, 0.2694538100612633, 0.26923382460068257, 0.2690067194970856, 0.2690051905880244, 0.2688491332324144, 0.2687555623617937, 0.26861014569429986, 0.26849059590099095]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "loss_values = model.loss_curve_\n",
    "print (loss_values)\n",
    "plt.plot(loss_values)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(\"..\",\"Resources\", \"loc_dict.csv\")\n",
    "reader = csv.reader(open(file, 'r'))\n",
    "loc_dict = {}\n",
    "for row in reader:\n",
    "    #print(row)\n",
    "    k, v = row\n",
    "    loc_dict[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = os.path.join(\"..\",\"Resources\", \"type_dict.csv\")\n",
    "reader = csv.reader(open(file, 'r'))\n",
    "type_dict = {}\n",
    "for row in reader:\n",
    "    #print(row)\n",
    "    k, v = row\n",
    "    type_dict[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "month = 6\n",
    "hour = 15\n",
    "day_of_week = 4\n",
    "location_description = int(loc_dict.get('AIRPORT BUILDING NON-TERMINAL - SECURE AREA'))\n",
    "primary_type =int(type_dict.get('THEFT'))\n",
    "\n",
    "filename='MLP_model.pkl'\n",
    "# Load from file\n",
    "with open(filename, 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "    \n",
    "print(model.predict([[month, hour, day_of_week,location_description,primary_type]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evans\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator DecisionTreeClassifier from version 0.22.2.post1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\evans\\Anaconda3\\envs\\PythonData\\lib\\site-packages\\sklearn\\base.py:334: UserWarning: Trying to unpickle estimator RandomForestClassifier from version 0.22.2.post1 when using version 0.23.1. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "month = 6\n",
    "hour = 15\n",
    "day_of_week = 4\n",
    "location_description = int(loc_dict.get('AIRPORT BUILDING NON-TERMINAL - SECURE AREA'))\n",
    "primary_type =int(type_dict.get('THEFT'))\n",
    "\n",
    "filename='RF_model.sav'\n",
    "# Load from file\n",
    "model = joblib.load(filename)\n",
    "    \n",
    "print(model.predict([[month, hour, day_of_week,location_description,primary_type]]))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
