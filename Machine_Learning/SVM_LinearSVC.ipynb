{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Check Chicago Crime Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import 2016-2019 crime data\n",
    "crime_2016 = os.path.join(\"..\",\"Resources\", \"crime_clean_2016.csv\") \n",
    "crime_2017 = os.path.join(\"..\",\"Resources\", \"crime_clean_2017.csv\")\n",
    "crime_2018 = os.path.join(\"..\",\"Resources\", \"crime_clean_2018.csv\")\n",
    "crime_2019 = os.path.join(\"..\",\"Resources\", \"crime_clean_2019.csv\")\n",
    "\n",
    "crime_2016_df_final = pd.read_csv(crime_2016)\n",
    "crime_2017_df_final = pd.read_csv(crime_2017)\n",
    "crime_2018_df_final = pd.read_csv(crime_2018)\n",
    "\n",
    "# 2019 is the test data\n",
    "test_data = pd.read_csv(crime_2019)\n",
    "\n",
    "# Join datasets for 2016, 2017, and 2018 for the training data\n",
    "join1 = crime_2016_df_final.append(crime_2017_df_final)\n",
    "training_data = join1.append(crime_2018_df_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number training records 2016-2018\n",
    "training_data.id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data types\n",
    "training_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#number test records 2019\n",
    "test_data.id.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to Convert data to numbers\n",
    "from sklearn import preprocessing\n",
    "def convert(data):\n",
    "    number = preprocessing.LabelEncoder()\n",
    "    data['date'] = number.fit_transform(data.date)\n",
    "    data['time'] = number.fit_transform(data.time)\n",
    "    data['block'] = number.fit_transform(data.block)\n",
    "    data['description'] = number.fit_transform(data.description)\n",
    "    data['location_description'] = number.fit_transform(data.location_description)\n",
    "    data['iucr'] = number.fit_transform(data.iucr)\n",
    "    data['fbi_code'] = number.fit_transform(data.fbi_code)\n",
    "    data['primary_type'] = number.fit_transform(data.primary_type)\n",
    "    data['domestic'] = number.fit_transform(data.domestic)\n",
    "    data['latitude'] = number.fit_transform(data.latitude)\n",
    "    data['longitude'] = number.fit_transform(data.longitude)\n",
    "    #data['arrest'] = number.fit_transform(data.arrest)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to drop unneeded columns/keeping only features needed for model\n",
    "def set_data(data):\n",
    "    data = (data[[\n",
    "              #'date'\n",
    "              #'day'\n",
    "              'month'\n",
    "              #,'year'\n",
    "              #,'time'\n",
    "              ,'hour'\n",
    "              #,'month_day'\n",
    "              ,'day_of_week'\n",
    "              ,'district'\n",
    "              #,'block'\n",
    "              ,'ward'\n",
    "              ,'beat'\n",
    "              ,'community_area'\n",
    "              ,'description'\n",
    "              ,'location_description'\n",
    "              #,'x_coordinate'\n",
    "              #,'y_coordinate'\n",
    "              ,'iucr'\n",
    "              ,'fbi_code'\n",
    "              ,'primary_type'\n",
    "              ,'domestic'\n",
    "              #,'latitude'\n",
    "              #,'longitude'\n",
    "            ]])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LabelEncode the data\n",
    "train_enc_data = convert(training_data)\n",
    "test_enc_data = convert(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the training and test labels/features\n",
    "X_train=set_data(train_enc_data)\n",
    "X_test=set_data(test_enc_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the target to be arrest with target name true/false\n",
    "y_train = train_enc_data[\"arrest\"]\n",
    "y_test = test_enc_data[\"arrest\"]\n",
    "#target_names = [\"True\", \"False\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = X_train.columns\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features/labels\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preview test data\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape training data\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#shape test data\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale the data for SVM, requires normalization\n",
    "#reference: https://scikit-learn.org/stable/auto_examples/preprocessing/plot_scaling_importance.html\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "y_train = np.array(y_train).reshape((len(y_train), 1),order='C')\n",
    "y_test = np.array(y_test).reshape((len(y_test), 1),order='C')\n",
    "\n",
    "X_scaler = StandardScaler().fit(X_train)\n",
    "\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model is faster with C-contiguous data\n",
    "#reference: https://scikit-learn.org/stable/modules/svm.html\n",
    "X_train_scaled = np.asarray(X_train_scaled, order='C')\n",
    "X_test_scaled = np.asarray(X_test_scaled, order='C')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Support vector machine Linear Support Vector Classification \n",
    "# reference: https://ogrisel.github.io/scikit-learn.org/sklearn-tutorial/modules/generated/sklearn.svm.LinearSVC.html\n",
    "# Similar to SVC with parameter kernel=’linear’, but implemented in terms of liblinear rather than libsvm, \n",
    "# so it has more flexibility in the choice of penalties and loss functions and should scale better to\n",
    "# large numbers of samples.\n",
    "# dual: Select the algorithm to either solve the dual or primal optimization problem. \n",
    "# Prefer dual=False when n_samples > n_features.\n",
    "\n",
    "from sklearn.svm import LinearSVC \n",
    "model = LinearSVC(dual=False)\n",
    "model.fit(X_train_scaled, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Accuracy\n",
    "print('Test Acc: %.3f' % model.score(X_test_scaled, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification report\n",
    "from sklearn.metrics import classification_report\n",
    "predictions = model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
